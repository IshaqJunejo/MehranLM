# Scripts

## Overview

This directory contains scripts for processing the corpus, including cleaning and deduplication, exploratory data analysis (EDA), and tokenization.
Each subfolder contains specific scripts focused on a particular aspect of corpus processing.

## Directory Structure

- `cleaning/`
  - `corpus_cleaning.py`, cleans the corpus by removing unwanted symbols, characters, and diacritics; it also performs deduplication on each file.
- `EDA/`
  - `unique_char.py`, a script to identify unique characters in the corpus.
  - `unique_chars.txt`, contains all the unique characters in our corpus, generated by `unique_char.py`.
  - `corpus_stats.py`, calculates the frequency of each character in our entire corpus and writes that information to a file.
  - `char_frequency.txt`, contains each character, its name, and how many times it appears in our corpus. This file is generated by `corpus_stats.py`.
- `tokenization/`
  - `BPE_merges.py`, implements Byte-Pair-Encoding (BPE) for tokenization.
  - `merges.txt`, contains merge operations used in BPE, generated by `BPE_merges.py`.
  - `tokenizer.py`, tokenizer script that utilizes the BPE merges from `merges.txt`.
  - `id_to_token.json`, Mapping from IDs to tokens.
  - `token_to_id.json`, Mapping from tokens to IDs.
